\section{Introductio(neocomplete_start_auto_complete)n}
In this project, we explore different ways to improve results of two binary
classifiers without hyperparameter tuning - Logistic regression and
Random forests. The methods used are of the over-sampling type and are as
follows: Random over-sampling, SMOTE, ADASYN, and balanced weighting of
inputs.

The data set chosen is payment
data from an important bank in Taiwan, where the data describes credit card 
holders, and the goal is predicting whether a customer will default the 
next payment or not.

The data set is provided by UCI and has also been the subject of study by \cite{ComparisonData}): 
\href{https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients}{Credit Card Data}

The report gives a brief introduction to the classifiers, and the methods
used to measure their performance.

We will compare some of our figures to those from the article ~\cite{ComparisonData}
, because it is
a nice reference point. 

Code, data and figures are available at the following GitHub address:
\href{https://github.com/geirtul/fys-stk4155/tree/master/project3}{GitHub repository}


