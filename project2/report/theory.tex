\section{Theory}

%Consider putting in: general on ML 

%Consider adding theory from project1? 
%Until then: 
As the theory behond the three regression methods used as well as error 
estimates and the bootstrap method is covered in the previous 
project, we will not restate it here.

\subsection{The Ising model} 
The ising model is a simple binary value system where the variables
in the model can take only two values. For examle \(\pm 1\) or \(0\) and \(1\). 
~\cite{Project2} 

We will look at the physicist's approach, and call the variables for spin.
~\cite{Project2}

Given an ensamble of random spin configurations we can assign an energy to
each state, using the 1D Ising model with nearest-neighbor interactions: 

\begin{equation}
	E = -J\sum\limits_{j=1}^N S_jS_{j+1} 
\end{equation}
J is the nearest-neighbor spin interaction, and \(S_j \epsilon {\pm 1}\) is a 
spin variable. N is the chain length. 
~\cite{HighBias}~\cite{Project2} 

In one dimension, this model has no phase transitions at finite temperature.
~\cite{Project2} 

To get a spin model with pairwise interactions between every pair of variables,
we choose the following model class: 

\begin{equation}
	E_{model}[S^i] = -\sum\limits_{j=1}^N\sum\limits_{k=1}^N J_{j,k} S_j^iS_{k}^i
\end{equation}
~\cite{HighBias} 

In this equation \(i\) represents a particular spin configuration. ~\cite{Project2}

The goal with this model is to determine the interaction matrix \(J_{j,k}\). 
As the model is linear in \(\mathbf{J}\), it is possible to use
linear regression.  

The problem can be recast on the form

\begin{equation}
	E_{model}^i = \mathbf{x}^i \cdot \mathbf{J}  
\end{equation}

\subsection{Logistic regression and classification problems}
Differently to linear regression, classification problems 
are concerned with outcomes taking the form of discrete variables. 
For a specific physical problem, we'd like to identify its state, say whether
it is an ordered of disordered system. ~\cite{LectureNotes-FysStk}

Logistic regression can be used to define the phases of the Ising
model.~\cite{LectureNotes} 

Configurations representing states below the critical temperature are called
ordered states, while those above the critical temperature are called 
disorderes states. ~\cite{Project2} 

The theoretical critical temperature for a phase transition is 
\(T_C \approx 2.269\). 

\subsection{Cost functions} 
In order for the network and the logistic regressor to improve it needs a way to 
track how it's performing. This is the purpose of a cost function. Essentially,
the cost function says something about how wrong the model is in classifying the
input. The ojective in machine learning, and logistic regression, is then to minimize
this error.

The cost function used in this project is called the \textbf{cross-entropy}, or the
'negative log likelihood', and takes the form
\begin{equation}\label{eq:cross-entropy}
	\mathcal{C}(\hat{\beta})=-\sum_{i=1}^n  \left(y_i(\beta_0+\beta_1x_i) -\log{(1+\exp{(\beta_0+\beta_1x_i)})}\right)
\end{equation}

\subsection{Gradient Descent solver}
To minimize the cost function, one of the most widely used methods is Gradient Descent.


\begin{equation}\label{eq:delta-c}
	\frac{\partial \mathcal{C}(\hat{\beta})}{\partial \hat{\beta}} = -\hat{X}^T\left(\hat{y}-\hat{p}\right)
\end{equation}

\subsection{Accuracy score}
To measure the accuracy of the network, an accuracy score is defined as:
\begin{equation*}
	\text{Accuracy} = \frac{\sum_{i=1}^{n} I(t_i = y_i)}{n}
\end{equation*}
which is simply the number of correctly labeled states divided by the
total number of states. In the equation above, $I$ is the indicator function,
1 if $t_i = y_i$ and 0 otherwise. $t_i$ is the known correct label and $y_i$ is the
label output by the network.





