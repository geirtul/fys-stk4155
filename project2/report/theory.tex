\section{Theory}

As the theory behond the three regression methods used as well as error 
estimates and the bootstrap method is covered in the previous 
project, we will not restate it here.
Alternatively, see \cite{HighBias} and/or \cite{LectureNotes-FysStk}.

\subsection{The Ising model}\label{seq:isingtheory}
The ising model is a simple binary value system where the variables
in the model can take only two values. For examle \(\pm 1\) or \(0\) and \(1\). 
~\cite{Project2} 

We will look at the physicist's approach, and call the variables for spin.
~\cite{Project2}

Given an ensamble of random spin configurations we can assign an energy to
each state, using the 1D Ising model with nearest-neighbor interactions: 

\begin{equation}
	E = -J\sum\limits_{j=1}^N S_jS_{j+1} 
\end{equation}
J is the nearest-neighbor spin interaction, and \(S_j \epsilon {\pm 1}\) is a 
spin variable. N is the chain length. 
~\cite{HighBias}~\cite{Project2} 

In one dimension, this model has no phase transitions at finite temperature.
~\cite{Project2} 

To get a spin model with pairwise interactions between every pair of variables,
we choose the following model class: 

\begin{equation}
	E_{model}[S^i] = -\sum\limits_{j=1}^N\sum\limits_{k=1}^N J_{j,k} S_j^iS_{k}^i
\end{equation}
~\cite{HighBias} 

In this equation \(i\) represents a particular spin configuration. ~\cite{Project2}

The goal with this model is to determine the interaction matrix \(J_{j,k}\). 
As the model is linear in \(\mathbf{J}\), it is possible to use
linear regression.  

The problem can be recast on the form

\begin{equation}
	E_{model}^i = \mathbf{x}^i \cdot \mathbf{J}  
\end{equation}

\subsection{Logistic regression and classification problems}\label{seq:logistic}
Differently to linear regression, classification problems 
are concerned with outcomes taking the form of discrete variables. 
For a specific physical problem, we'd like to identify its state, say whether
it is an ordered of disordered system. ~\cite{LectureNotes-FysStk}

Logistic regression can be used to define the phases of the Ising
model.~\cite{LectureNotes} 

Configurations representing states below the critical temperature are called
ordered states, while those above the critical temperature are called 
disorderes states. ~\cite{Project2} 

The theoretical critical temperature for a phase transition is 
\(T_C \approx 2.269\). 

\subsection{Cost functions}\label{seq:cost}  
In order for a network and a logistic regressor to improve it needs a way to 
track how it's performing. This is the purpose of a cost function. Essentially,
the cost function says something about how wrong the model is in classifying the
input. The objective in machine learning, and logistic regression, is then to minimize
this error.

The cost function used in this project is called the \textbf{cross-entropy}, or the
'negative log likelihood', and takes the form
\begin{equation}\label{eq:cross-entropy}
	\mathcal{C}(\hat{\beta})=-\sum_{i=1}^n  \left(y_i(\beta_0+\beta_1x_i) -\log{(1+\exp{(\beta_0+\beta_1x_i)})}\right)
\end{equation}

\subsection{Gradient Descent}\label{seq:gradient}
Minimizing the cost function is done using Gradient Descent.
The jist of it is that in order to optimize the weights or coefficients, 
and biases to minimize the cost function, one can change their values to 

\begin{equation}\label{eq:delta-c}
	\frac{\partial \mathcal{C}(\hat{\beta})}{\partial \hat{\beta}} = -\hat{X}^T\left(\hat{y}-\hat{p}\right)
\end{equation}

\subsubsection{Stochastic gradient decent} 
The stochastic gradient decent method address some of the shortcomings 
of the normal gradient decent method. The gradient decent method is 
for instance sensitive to the choise of learning rate ~\cite{LectureNotes-FysStk}.

The underlying idea of stochastic gradient decent comes form observing
that the cost function we want to minimize, almost always can be written as 
a sum over \(n\) data points. ~\cite{LectureNotes-FysStk}. Which gives

\begin{equation}
	C(\beta) = \sum\limits_{i=1}^n c_i (\mathbf{x}_i\beta)
\end{equation} ~\cite{LectureNotes-FysStk}

This means that we also can find the gradient as a sum over i gradients
as follows: 

\begin{equation}
	\Delta_{\beta} C(\beta) = \sum\limits_{i}^n \Delta_{\beta}c_i (\mathbf{x}_i\beta)
\end{equation} ~\cite{LectureNotes-FysStk}

Randomness is included by only taking the gradient on a subset of data. 

\subsection{Accuracy score}\label{seq:accuracy} 
To measure the accuracy of the network, an accuracy score is defined as:
\begin{equation*}
	\text{Accuracy} = \frac{\sum_{i=1}^{n} I(t_i = y_i)}{n}
\end{equation*}
which is simply the number of correctly labeled states divided by the
total number of states. In the equation above, $I$ is the indicator function,
1 if $t_i = y_i$ and 0 otherwise. $t_i$ is the known correct label and $y_i$ is the
label output by the network.

\subsection{Neural Network}
The concept of a neural network is essentially to mimick how neurons in the
brain are connected and learn. The network consists of interconnected layers
of neurons, or 'nodes'. In the type of network used in this project, a
Feed Forward Neural Network (FFNN), each node in a layer has a connection to
every single node in the previous layer. As an input signal is 'fed' forward
through the network, each node in each layer will 'fire' or 'activate'
based on the sum of the signals from the nodes in the preceding layer, until
the signal reaches the output layer which, in this project, outputs a
probability that the original input is in one of two classes.
In short, the FFNN is a binary classifier which takes an input and outputs
the likelihood of that input belonging to one of the classes.

The network doesn't know how to do this without first being trained.
Training the network involves analyzing the error the network makes in
classifying an input, and propagating this error backwards through the network
such that the next time an input of that class is seen, the network will be
better at classifying it.
An example of this type of binary classification could be to say whether or
not there is a cat in a picture.

Numerous articles and books are available on the subject of neural networks,
so for an in-depth explanation of the concepts involved (especially the
backpropagation of error), we recommend seeking out these texts.
Examples are the online book \href{http://neuralnetworksanddeeplearning.com/}{Nielsen's}, or the article by Mehta et al (\cite{HighBias}).


